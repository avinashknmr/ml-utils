<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>ml_utils.measure API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{font-family:Avenir,Calibri,Verdana;line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ml_utils.measure</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import pandas as pd
import numpy as np
from sklearn.metrics import roc_curve, auc, confusion_matrix, precision_score, recall_score, f1_score
from sklearn.metrics import average_precision_score, precision_recall_curve

from .woe_binning import woe_binning, woe_binning_2, woe_binning_3

__pdoc__ = {}
__pdoc__[&#39;ml_utils.measure.Metrics&#39;] = False

class Metrics:
    def __init__(self, df, actual, prediction):
        self.df = df
        self.target = actual
        self.actual = df[actual]
        self.prediction = df[prediction]
        self.gains = self.calculate_gains()
        self.ks = self.ks()
        self.gini = self.gini()
        self.tn, self.fp, self.fn, self.tp, self.precision, self.recall, self.f1_score = self.precision_recall_f1_score()

    def calculate_gains(self):
        &#34;&#34;&#34;Returns a pandas dataframe with gains along with KS and Gini calculated&#34;&#34;&#34;
        self.df[&#39;scaled_score&#39;] = (self.df[&#39;positive_probability&#39;]*1000000).round(0)
        gains = self.df.groupby(&#39;scaled_score&#39;)[self.target].agg([&#39;count&#39;,&#39;sum&#39;])
        gains.columns = [&#39;total&#39;,&#39;responders&#39;]
        gains.reset_index(inplace=True)
        gains.sort_values(by=&#39;scaled_score&#39;, ascending=False)
        gains[&#39;non_responders&#39;] = gains[&#39;total&#39;] - gains[&#39;responders&#39;]
        gains[&#39;cum_resp&#39;] = gains[&#39;responders&#39;].cumsum()
        gains[&#39;cum_non_resp&#39;] = gains[&#39;non_responders&#39;].cumsum()
        gains[&#39;total_resp&#39;] = gains[&#39;responders&#39;].sum()
        gains[&#39;total_non_resp&#39;] = gains[&#39;non_responders&#39;].sum()
        gains[&#39;perc_resp&#39;] = (gains[&#39;responders&#39;]/gains[&#39;total_resp&#39;])*100
        gains[&#39;perc_non_resp&#39;] = (gains[&#39;non_responders&#39;]/gains[&#39;total_non_resp&#39;])*100
        gains[&#39;perc_cum_resp&#39;] = gains[&#39;perc_resp&#39;].cumsum()
        gains[&#39;perc_cum_non_resp&#39;] = gains[&#39;perc_non_resp&#39;].cumsum()
        gains[&#39;k_s&#39;] = gains[&#39;perc_cum_resp&#39;] - gains[&#39;perc_cum_non_resp&#39;]
        return gains

    def get_threshold(self):
        &#34;&#34;&#34;Returns a pandas dataframe with y_pred based on threshold from roc_curve.&#34;&#34;&#34;
        fpr, tpr, threshold = roc_curve(self.actual, self.prediction)
        threshold_cutoff_df = pd.DataFrame({&#39;fpr&#39;: fpr, &#39;tpr&#39;: tpr, &#39;threshold&#39;: threshold})
        threshold_cutoff_df[&#39;distance&#39;] = ((threshold_cutoff_df[&#39;fpr&#39;]-0)**2+(threshold_cutoff_df[&#39;tpr&#39;]-1)**2)**0.5
        threshold_cutoff_df[&#39;distance_diff&#39;] = abs(threshold_cutoff_df[&#39;distance&#39;].diff(periods=1))
        for index, rows in threshold_cutoff_df.iterrows():
            if index != 0 and index != threshold_cutoff_df.shape[0]-1:
                curr_val = threshold_cutoff_df.loc[index, &#39;distance_diff&#39;]
                prev_val = threshold_cutoff_df.loc[index-1, &#39;distance_diff&#39;]
                next_val = threshold_cutoff_df.loc[index+1, &#39;distance_diff&#39;]
                if curr_val&gt;prev_val and curr_val&gt;next_val:
                    threshold_cutoff = threshold_cutoff_df.loc[index, &#39;threshold&#39;]
                    break
        return threshold_cutoff

    def gini(self):
        fpr, tpr, threshold = roc_curve(self.actual, self.prediction)
        auroc = auc(fpr, tpr)
        gini  = 2*auroc -1
        return gini

    def ks(self):
        gains  = self.gains()
        return gains[&#39;k_s&#39;].max()

    def precision_recall_f1_score(self):
        threshold_cutoff = self.get_threshold()
        self.y_pred = np.where(self.prediction&gt;=threshold_cutoff,1,0)
        self.df[&#39;y_pred&#39;] = self.y_pred
        tn, fp, fn, tp = confusion_matrix(self.actual, self.y_pred).ravel()
        precision = precision_score(self.actual, self.y_pred)
        recall = recall_score(self.actual, self.y_pred)
        f1 = f1_score(self.actual, self.y_pred)
        return tn, fp, fn, tp, precision, recall, f1

    def to_dict(self):
        return {&#39;ks&#39;: self.ks, &#39;gini&#39;: self.gini, &#39;tn&#39;: self.tn, &#39;tp&#39;: self.tp, &#39;fn&#39;: self.fn, &#39;fp&#39;: self.fp, &#39;precision&#39;: self.precision, &#39;recall&#39;: self.recall, &#39;f1_score&#39;: self.f1_score}

def standard_metrics(df, target_col, prediction_col):
    &#34;&#34;&#34;Returns a dict with all metrics - Gini, KS, Precision, Recall, F1 Score, True Negative, True Positive, False Positive, False Negative.&#34;&#34;&#34;
    metrics = Metrics(df, target_col, prediction_col)
    return metrics.to_dict()

def quick_psi(dev, val):
    &#34;&#34;&#34;Calculate PSI from 2 arrays - dev and val&#34;&#34;&#34;
    return sum([(a-b)*np.log(a/b) for (a,b) in zip(dev,val)])

def psi(dev, val, target=&#39;positive_probability&#39;, n_bins=10):
    &#34;&#34;&#34;
    Returns a pandas dataframe with psi column (Population Stability Index) after creating 10 deciles.
    Code includes creating score calculation using round(500-30 x log(100 x (p/(1-p))), 0) where p is probability.
    We need to pass both dev and val at same time to apply same bins created on dev dataframe.
    &#34;&#34;&#34;
    dev[&#39;score&#39;] = dev[target].apply(lambda x: round(500-30*np.log2(100*(x/(1-x))), 0))
    val[&#39;score&#39;] = val[target].apply(lambda x: round(500-30*np.log2(100*(x/(1-x))), 0))
    
    dev[&#39;bins&#39;], bins = pd.qcut(dev.score, n_bins, retbins=True, precision=0)
    bins = [int(i) if abs(i)!=np.inf else i for i in bins]
    val[bins] = pd.cut(val.score, bins)

    dev_bins = dev.bins.value_counts(sort=False, normalize=True)
    val_bins = val.bins.value_counts(sort=False, normalize=True)

    psi_ = pd.concat([dev_bins, val_bins], axis=1)
    psi_.columns = [&#39;dev&#39;, &#39;val&#39;]
    psi_[&#39;psi&#39;] = (psi_.dev - psi_.val)*np.log(psi_.dev/psi_.val)
    return psi_

def gsi(data, col=&#39;GENDER&#39;, col_val=&#39;F&#39;, target=&#39;positive_probability&#39;, n_bins=10):
    &#34;&#34;&#34;
    Returns a pandas dataframe with gsi columns (Group Stability Index) after creating n bins.
    Args:
        data: pandas dataframe
        col: Columns on which GSI has to be calculated (ex: Gender column)
        col_val: selected value will be compared with rest of the values (ex: F vs Rest)
        target: score column
        n_bins: number of bins to be created (Default=10)
    &#34;&#34;&#34;
    df = data.copy()
    df[&#39;decile&#39;] = pd.qcut(df[target], n_bins, labels=False)
    df.loc[df[col]!=col_val, col] = &#39;Rest&#39;
    pivot_ = df.groupby([&#39;decile&#39;, col])[target].count().unstack()
    pivot = pivot_.div(pivot_.sum(axis=0), axis=1)
    pivot[&#39;gsi&#39;] = (pivot[col_val]-pivot[&#39;Rest&#39;])*np.log(pivot[col_val]/pivot[&#39;Rest&#39;])
    return pivot

def chi_square(df, suffix=&#39;_dev&#39;):
    &#34;&#34;&#34;Returns a pandas dataframe with calculated fields - resp_rate, perc_dist, perc_non_resp, perc_resp, raw_odds, ln_odds, iv_bins, exp_resp, exp_non_resp, chi_square.&#34;&#34;&#34;
    df[&#39;resp_rate&#39;+suffix] = (df[&#39;responders&#39;+suffix]*100)/df[&#39;total&#39;+suffix]
    df[&#39;perc_dist&#39;+suffix] = (df[&#39;total&#39;+suffix]*100)/df.groupby(&#39;var_name&#39;)[&#39;total&#39;+suffix].transform(&#39;sum&#39;)
    df[&#39;perc_non_resp&#39;+suffix] = (df[&#39;non_responders&#39;+suffix]*100)/df.groupby(&#39;var_name&#39;)[&#39;non_responders&#39;+suffix].transform(&#39;sum&#39;)
    df[&#39;perc_resp&#39;+suffix] = (df[&#39;responders&#39;+suffix]*100)/df.groupby(&#39;var_name&#39;)[&#39;responders&#39;+suffix].transform(&#39;sum&#39;)
    df[&#39;raw_odds&#39;+suffix] = df.apply(lambda r: 0 if r[&#39;perc_resp&#39;+suffix]==0 else r[&#39;perc_non_resp&#39;+suffix]/r[&#39;perc_resp&#39;+suffix], axis=1)
    df[&#39;ln_odds&#39;+suffix] = df[&#39;raw_odds&#39;+suffix].apply(lambda x: 0 if abs(np.log(x))==np.inf else np.log(x))
    df[&#39;iv_bins&#39;+suffix] = (df[&#39;perc_non_resp&#39;+suffix]-df[&#39;perc_resp&#39;+suffix])*df[&#39;ln_odds&#39;+suffix]/100
    df[&#39;exp_resp&#39;+suffix] = df[&#39;total&#39;+suffix]*df.groupby(&#39;var_name&#39;)[&#39;responders&#39;+suffix].transform(&#39;sum&#39;)/df.groupby(&#39;var_name&#39;)[&#39;total&#39;+suffix].transform(&#39;sum&#39;)
    df[&#39;exp_non_resp&#39;+suffix] = df[&#39;total&#39;+suffix]*df.groupby(&#39;var_name&#39;)[&#39;non_responders&#39;+suffix].transform(&#39;sum&#39;)/df.groupby(&#39;var_name&#39;)[&#39;total&#39;+suffix].transform(&#39;sum&#39;)
    df[&#39;chi_square&#39;+suffix] = (((df[&#39;responders&#39;+suffix]-df[&#39;exp_resp&#39;+suffix])**2)/df[&#39;exp_resp&#39;+suffix]) + (((df[&#39;non_responders&#39;+suffix]-df[&#39;exp_non_resp&#39;+suffix])**2)/df[&#39;exp_non_resp&#39;+suffix])
    return df

def woe_bins(df, var_name, resp_name, suffix=&#39;_dev&#39;, var_cuts=None):
    &#34;&#34;&#34;
    Returns a pandas dataframe, var_cuts after creating bins basd on `ml_utils.woe_binning`.
    Returns:
        df: pandas dataframe has var_cuts_string, total, responders, non_responders, var_name (with _dev or _val suffix)
        var_cuts: list of Interval items to be used on val file.
    &#34;&#34;&#34;
    df1 = df[[resp_name, var_name]]
    if (np.issubdtype(df1[var_name].dtype, np.number)):
        n = df1[var_name].nunique()
        if var_cuts is None:
            suffix = &#39;_dev&#39;
            var_cuts = woe_binning_3(df1, resp_name, var_name, 0.05, 0.00001, 0, 50, &#39;bad&#39;, &#39;good&#39;)
        df[&#39;var_binned&#39;] = pd.cut(df[var_name], var_cuts, right=True, labels=None, retbins=False, precision=10, include_lowest=False)
        var_min = float(df1[var_name].min())
        var_max = float(df1[var_name].max())
        summ_df = df1.groupby(&#39;var_binnied&#39;)[resp_name].agg([&#39;count&#39;,&#39;sum&#39;]).reset_index()
        summ_df[&#39;delta&#39;] = summ_df[&#39;count&#39;] - summ_df[&#39;sum&#39;]
        summ_df[&#39;var_name&#39;] = var_name
        summ_df.columns = [&#39;var_cuts&#39;, &#39;total&#39;+suffix, &#39;responders&#39;+suffix, &#39;non_responders&#39;+suffix, &#39;var_name&#39;]
        summ_df[&#39;var_cuts_string&#39;+suffix] = summ_df.var_cuts.apply(lambda x: str(x.left if x.left!=-np.inf else var_min)+&#39; To &#39;+str(x.right if x.right!=np.inf else var_max))
    else:
        df1[var_name].fillna(&#39;Blank&#39;, inplace=True)
        summ_df = df1.groupby(var_name)[resp_name].agg([&#39;count&#39;,&#39;sum&#39;]).reset_index()
        summ_df[&#39;delta&#39;] = summ_df[&#39;count&#39;] - summ_df[&#39;sum&#39;]
        summ_df[&#39;var_name&#39;] = var_name
        summ_df.columns = [&#39;var_cuts_string&#39;+suffix, &#39;total&#39;+suffix, &#39;responders&#39;+suffix, &#39;non_responders&#39;+suffix, &#39;var_name&#39;]
        summ_df[&#39;var_cuts&#39;] = summ_df[&#39;var_cuts_string&#39;+suffix]
    return summ_df[summ_df[&#39;total&#39;+suffix]!=0], var_cuts

def csi(dev_df, val_df, var_list, resp_name):
    &#34;&#34;&#34;Returns a pandas dataframe with csi, csi_var, perc_csi columns (Charecteristic Stability Index) calculated based on both dev and val dataframes.&#34;&#34;&#34;
    dev_dfs = []
    var_cuts = {}
    for var_name in var_list:
        summ_df, cut = woe_bins(dev_df, var_name, resp_name, &#39;_dev&#39;)
        dev_dfs.append(summ_df)
        var_cuts[var_name] = cut
    
    dev = pd.concat(dev_dfs, axis=0)
    dev = chi_square(dev, &#39;_dev&#39;)

    val_dfs = []
    val_cuts = {}
    for var_name in var_list:
        val_summ_df, val_cut = woe_bins(val_df, var_name, resp_name, &#39;_val&#39;, var_cuts[var_name])
        val_dfs.append(val_summ_df)
        val_cuts[var_name] = val_cut

    val = pd.concat(val_dfs, axis=0)
    val = chi_square(val, &#39;_val&#39;)

    final = pd.merge(dev, val, how=&#39;left&#39;, on=[&#39;var_name&#39;, &#39;var_cuts&#39;], suffixes=[&#39;_dev&#39;,&#39;_val&#39;])
    
    final[&#39;csi&#39;] = ((final[&#39;perc_dist_dev&#39;]-final[&#39;perc_dist_val&#39;])/100)*np.log(final[&#39;perc_dist_dev&#39;]/final[&#39;perc_dist_val&#39;])
    final[&#39;csi_var&#39;] = final.groupby(&#39;var_name&#39;)[&#39;csi&#39;].transform(&#39;sum&#39;)
    final[&#39;perc_csi&#39;] = (100*final.groupby(&#39;var_name&#39;)[&#39;csi&#39;].transform(&#39;cumsum&#39;))/final.groupby(&#39;var_name&#39;)[&#39;csi&#39;].transform(&#39;sum&#39;)
    return final

def get_decilewise_counts(df, target, bins=10, cutpoints=None):
    &#34;&#34;&#34;Returns a summarized pandas dataframe with total and responders for each decile based on positive_probability.&#34;&#34;&#34;
    if cutpoints is None:
        cutpoints = df[&#39;positive_probability&#39;].quantile(np.arange(0, bins+1)/bins).reset_index(drop=True)
        cutpoints = [0] + list(cutpoints) + [1]
    df[&#39;bins&#39;] = pd.cut(df[&#39;positive_probability&#39;], cutpoints)
    out_df = df.groupby(&#39;bins&#39;)[target].agg([&#39;count&#39;,&#39;sum&#39;]).sort_values(by=[&#39;bins&#39;], ascending=False).reset_index()
    out_df.columns = [&#39;band&#39;, &#39;total&#39;, &#39;responders&#39;]
    return out_df</code></pre>
</details>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-variables">Global variables</h2>
<dl>
<dt id="ml_utils.measure.Metrics"><code class="name">var <span class="ident">Metrics</span></code></dt>
<dd>
<div class="desc"><p>dummy</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class _BLACKLISTED_DUMMY:
    pass</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="ml_utils.measure.chi_square"><code class="name flex">
<span>def <span class="ident">chi_square</span></span>(<span>df, suffix='_dev')</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a pandas dataframe with calculated fields - resp_rate, perc_dist, perc_non_resp, perc_resp, raw_odds, ln_odds, iv_bins, exp_resp, exp_non_resp, chi_square.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def chi_square(df, suffix=&#39;_dev&#39;):
    &#34;&#34;&#34;Returns a pandas dataframe with calculated fields - resp_rate, perc_dist, perc_non_resp, perc_resp, raw_odds, ln_odds, iv_bins, exp_resp, exp_non_resp, chi_square.&#34;&#34;&#34;
    df[&#39;resp_rate&#39;+suffix] = (df[&#39;responders&#39;+suffix]*100)/df[&#39;total&#39;+suffix]
    df[&#39;perc_dist&#39;+suffix] = (df[&#39;total&#39;+suffix]*100)/df.groupby(&#39;var_name&#39;)[&#39;total&#39;+suffix].transform(&#39;sum&#39;)
    df[&#39;perc_non_resp&#39;+suffix] = (df[&#39;non_responders&#39;+suffix]*100)/df.groupby(&#39;var_name&#39;)[&#39;non_responders&#39;+suffix].transform(&#39;sum&#39;)
    df[&#39;perc_resp&#39;+suffix] = (df[&#39;responders&#39;+suffix]*100)/df.groupby(&#39;var_name&#39;)[&#39;responders&#39;+suffix].transform(&#39;sum&#39;)
    df[&#39;raw_odds&#39;+suffix] = df.apply(lambda r: 0 if r[&#39;perc_resp&#39;+suffix]==0 else r[&#39;perc_non_resp&#39;+suffix]/r[&#39;perc_resp&#39;+suffix], axis=1)
    df[&#39;ln_odds&#39;+suffix] = df[&#39;raw_odds&#39;+suffix].apply(lambda x: 0 if abs(np.log(x))==np.inf else np.log(x))
    df[&#39;iv_bins&#39;+suffix] = (df[&#39;perc_non_resp&#39;+suffix]-df[&#39;perc_resp&#39;+suffix])*df[&#39;ln_odds&#39;+suffix]/100
    df[&#39;exp_resp&#39;+suffix] = df[&#39;total&#39;+suffix]*df.groupby(&#39;var_name&#39;)[&#39;responders&#39;+suffix].transform(&#39;sum&#39;)/df.groupby(&#39;var_name&#39;)[&#39;total&#39;+suffix].transform(&#39;sum&#39;)
    df[&#39;exp_non_resp&#39;+suffix] = df[&#39;total&#39;+suffix]*df.groupby(&#39;var_name&#39;)[&#39;non_responders&#39;+suffix].transform(&#39;sum&#39;)/df.groupby(&#39;var_name&#39;)[&#39;total&#39;+suffix].transform(&#39;sum&#39;)
    df[&#39;chi_square&#39;+suffix] = (((df[&#39;responders&#39;+suffix]-df[&#39;exp_resp&#39;+suffix])**2)/df[&#39;exp_resp&#39;+suffix]) + (((df[&#39;non_responders&#39;+suffix]-df[&#39;exp_non_resp&#39;+suffix])**2)/df[&#39;exp_non_resp&#39;+suffix])
    return df</code></pre>
</details>
</dd>
<dt id="ml_utils.measure.csi"><code class="name flex">
<span>def <span class="ident">csi</span></span>(<span>dev_df, val_df, var_list, resp_name)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a pandas dataframe with csi, csi_var, perc_csi columns (Charecteristic Stability Index) calculated based on both dev and val dataframes.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def csi(dev_df, val_df, var_list, resp_name):
    &#34;&#34;&#34;Returns a pandas dataframe with csi, csi_var, perc_csi columns (Charecteristic Stability Index) calculated based on both dev and val dataframes.&#34;&#34;&#34;
    dev_dfs = []
    var_cuts = {}
    for var_name in var_list:
        summ_df, cut = woe_bins(dev_df, var_name, resp_name, &#39;_dev&#39;)
        dev_dfs.append(summ_df)
        var_cuts[var_name] = cut
    
    dev = pd.concat(dev_dfs, axis=0)
    dev = chi_square(dev, &#39;_dev&#39;)

    val_dfs = []
    val_cuts = {}
    for var_name in var_list:
        val_summ_df, val_cut = woe_bins(val_df, var_name, resp_name, &#39;_val&#39;, var_cuts[var_name])
        val_dfs.append(val_summ_df)
        val_cuts[var_name] = val_cut

    val = pd.concat(val_dfs, axis=0)
    val = chi_square(val, &#39;_val&#39;)

    final = pd.merge(dev, val, how=&#39;left&#39;, on=[&#39;var_name&#39;, &#39;var_cuts&#39;], suffixes=[&#39;_dev&#39;,&#39;_val&#39;])
    
    final[&#39;csi&#39;] = ((final[&#39;perc_dist_dev&#39;]-final[&#39;perc_dist_val&#39;])/100)*np.log(final[&#39;perc_dist_dev&#39;]/final[&#39;perc_dist_val&#39;])
    final[&#39;csi_var&#39;] = final.groupby(&#39;var_name&#39;)[&#39;csi&#39;].transform(&#39;sum&#39;)
    final[&#39;perc_csi&#39;] = (100*final.groupby(&#39;var_name&#39;)[&#39;csi&#39;].transform(&#39;cumsum&#39;))/final.groupby(&#39;var_name&#39;)[&#39;csi&#39;].transform(&#39;sum&#39;)
    return final</code></pre>
</details>
</dd>
<dt id="ml_utils.measure.get_decilewise_counts"><code class="name flex">
<span>def <span class="ident">get_decilewise_counts</span></span>(<span>df, target, bins=10, cutpoints=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a summarized pandas dataframe with total and responders for each decile based on positive_probability.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def get_decilewise_counts(df, target, bins=10, cutpoints=None):
    &#34;&#34;&#34;Returns a summarized pandas dataframe with total and responders for each decile based on positive_probability.&#34;&#34;&#34;
    if cutpoints is None:
        cutpoints = df[&#39;positive_probability&#39;].quantile(np.arange(0, bins+1)/bins).reset_index(drop=True)
        cutpoints = [0] + list(cutpoints) + [1]
    df[&#39;bins&#39;] = pd.cut(df[&#39;positive_probability&#39;], cutpoints)
    out_df = df.groupby(&#39;bins&#39;)[target].agg([&#39;count&#39;,&#39;sum&#39;]).sort_values(by=[&#39;bins&#39;], ascending=False).reset_index()
    out_df.columns = [&#39;band&#39;, &#39;total&#39;, &#39;responders&#39;]
    return out_df</code></pre>
</details>
</dd>
<dt id="ml_utils.measure.gsi"><code class="name flex">
<span>def <span class="ident">gsi</span></span>(<span>data, col='GENDER', col_val='F', target='positive_probability', n_bins=10)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a pandas dataframe with gsi columns (Group Stability Index) after creating n bins.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong></dt>
<dd>pandas dataframe</dd>
<dt><strong><code>col</code></strong></dt>
<dd>Columns on which GSI has to be calculated (ex: Gender column)</dd>
<dt><strong><code>col_val</code></strong></dt>
<dd>selected value will be compared with rest of the values (ex: F vs Rest)</dd>
<dt><strong><code>target</code></strong></dt>
<dd>score column</dd>
<dt><strong><code>n_bins</code></strong></dt>
<dd>number of bins to be created (Default=10)</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def gsi(data, col=&#39;GENDER&#39;, col_val=&#39;F&#39;, target=&#39;positive_probability&#39;, n_bins=10):
    &#34;&#34;&#34;
    Returns a pandas dataframe with gsi columns (Group Stability Index) after creating n bins.
    Args:
        data: pandas dataframe
        col: Columns on which GSI has to be calculated (ex: Gender column)
        col_val: selected value will be compared with rest of the values (ex: F vs Rest)
        target: score column
        n_bins: number of bins to be created (Default=10)
    &#34;&#34;&#34;
    df = data.copy()
    df[&#39;decile&#39;] = pd.qcut(df[target], n_bins, labels=False)
    df.loc[df[col]!=col_val, col] = &#39;Rest&#39;
    pivot_ = df.groupby([&#39;decile&#39;, col])[target].count().unstack()
    pivot = pivot_.div(pivot_.sum(axis=0), axis=1)
    pivot[&#39;gsi&#39;] = (pivot[col_val]-pivot[&#39;Rest&#39;])*np.log(pivot[col_val]/pivot[&#39;Rest&#39;])
    return pivot</code></pre>
</details>
</dd>
<dt id="ml_utils.measure.psi"><code class="name flex">
<span>def <span class="ident">psi</span></span>(<span>dev, val, target='positive_probability', n_bins=10)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a pandas dataframe with psi column (Population Stability Index) after creating 10 deciles.
Code includes creating score calculation using round(500-30 x log(100 x (p/(1-p))), 0) where p is probability.
We need to pass both dev and val at same time to apply same bins created on dev dataframe.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def psi(dev, val, target=&#39;positive_probability&#39;, n_bins=10):
    &#34;&#34;&#34;
    Returns a pandas dataframe with psi column (Population Stability Index) after creating 10 deciles.
    Code includes creating score calculation using round(500-30 x log(100 x (p/(1-p))), 0) where p is probability.
    We need to pass both dev and val at same time to apply same bins created on dev dataframe.
    &#34;&#34;&#34;
    dev[&#39;score&#39;] = dev[target].apply(lambda x: round(500-30*np.log2(100*(x/(1-x))), 0))
    val[&#39;score&#39;] = val[target].apply(lambda x: round(500-30*np.log2(100*(x/(1-x))), 0))
    
    dev[&#39;bins&#39;], bins = pd.qcut(dev.score, n_bins, retbins=True, precision=0)
    bins = [int(i) if abs(i)!=np.inf else i for i in bins]
    val[bins] = pd.cut(val.score, bins)

    dev_bins = dev.bins.value_counts(sort=False, normalize=True)
    val_bins = val.bins.value_counts(sort=False, normalize=True)

    psi_ = pd.concat([dev_bins, val_bins], axis=1)
    psi_.columns = [&#39;dev&#39;, &#39;val&#39;]
    psi_[&#39;psi&#39;] = (psi_.dev - psi_.val)*np.log(psi_.dev/psi_.val)
    return psi_</code></pre>
</details>
</dd>
<dt id="ml_utils.measure.quick_psi"><code class="name flex">
<span>def <span class="ident">quick_psi</span></span>(<span>dev, val)</span>
</code></dt>
<dd>
<div class="desc"><p>Calculate PSI from 2 arrays - dev and val</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def quick_psi(dev, val):
    &#34;&#34;&#34;Calculate PSI from 2 arrays - dev and val&#34;&#34;&#34;
    return sum([(a-b)*np.log(a/b) for (a,b) in zip(dev,val)])</code></pre>
</details>
</dd>
<dt id="ml_utils.measure.standard_metrics"><code class="name flex">
<span>def <span class="ident">standard_metrics</span></span>(<span>df, target_col, prediction_col)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a dict with all metrics - Gini, KS, Precision, Recall, F1 Score, True Negative, True Positive, False Positive, False Negative.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def standard_metrics(df, target_col, prediction_col):
    &#34;&#34;&#34;Returns a dict with all metrics - Gini, KS, Precision, Recall, F1 Score, True Negative, True Positive, False Positive, False Negative.&#34;&#34;&#34;
    metrics = Metrics(df, target_col, prediction_col)
    return metrics.to_dict()</code></pre>
</details>
</dd>
<dt id="ml_utils.measure.woe_bins"><code class="name flex">
<span>def <span class="ident">woe_bins</span></span>(<span>df, var_name, resp_name, suffix='_dev', var_cuts=None)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns a pandas dataframe, var_cuts after creating bins basd on <code><a title="ml_utils.woe_binning" href="woe_binning.html">ml_utils.woe_binning</a></code>.</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>df</code></dt>
<dd>pandas dataframe has var_cuts_string, total, responders, non_responders, var_name (with _dev or _val suffix)</dd>
<dt><code>var_cuts</code></dt>
<dd>list of Interval items to be used on val file.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def woe_bins(df, var_name, resp_name, suffix=&#39;_dev&#39;, var_cuts=None):
    &#34;&#34;&#34;
    Returns a pandas dataframe, var_cuts after creating bins basd on `ml_utils.woe_binning`.
    Returns:
        df: pandas dataframe has var_cuts_string, total, responders, non_responders, var_name (with _dev or _val suffix)
        var_cuts: list of Interval items to be used on val file.
    &#34;&#34;&#34;
    df1 = df[[resp_name, var_name]]
    if (np.issubdtype(df1[var_name].dtype, np.number)):
        n = df1[var_name].nunique()
        if var_cuts is None:
            suffix = &#39;_dev&#39;
            var_cuts = woe_binning_3(df1, resp_name, var_name, 0.05, 0.00001, 0, 50, &#39;bad&#39;, &#39;good&#39;)
        df[&#39;var_binned&#39;] = pd.cut(df[var_name], var_cuts, right=True, labels=None, retbins=False, precision=10, include_lowest=False)
        var_min = float(df1[var_name].min())
        var_max = float(df1[var_name].max())
        summ_df = df1.groupby(&#39;var_binnied&#39;)[resp_name].agg([&#39;count&#39;,&#39;sum&#39;]).reset_index()
        summ_df[&#39;delta&#39;] = summ_df[&#39;count&#39;] - summ_df[&#39;sum&#39;]
        summ_df[&#39;var_name&#39;] = var_name
        summ_df.columns = [&#39;var_cuts&#39;, &#39;total&#39;+suffix, &#39;responders&#39;+suffix, &#39;non_responders&#39;+suffix, &#39;var_name&#39;]
        summ_df[&#39;var_cuts_string&#39;+suffix] = summ_df.var_cuts.apply(lambda x: str(x.left if x.left!=-np.inf else var_min)+&#39; To &#39;+str(x.right if x.right!=np.inf else var_max))
    else:
        df1[var_name].fillna(&#39;Blank&#39;, inplace=True)
        summ_df = df1.groupby(var_name)[resp_name].agg([&#39;count&#39;,&#39;sum&#39;]).reset_index()
        summ_df[&#39;delta&#39;] = summ_df[&#39;count&#39;] - summ_df[&#39;sum&#39;]
        summ_df[&#39;var_name&#39;] = var_name
        summ_df.columns = [&#39;var_cuts_string&#39;+suffix, &#39;total&#39;+suffix, &#39;responders&#39;+suffix, &#39;non_responders&#39;+suffix, &#39;var_name&#39;]
        summ_df[&#39;var_cuts&#39;] = summ_df[&#39;var_cuts_string&#39;+suffix]
    return summ_df[summ_df[&#39;total&#39;+suffix]!=0], var_cuts</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ml_utils" href="index.html">ml_utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-variables">Global variables</a></h3>
<ul class="">
<li><code><a title="ml_utils.measure.Metrics" href="#ml_utils.measure.Metrics">Metrics</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="ml_utils.measure.chi_square" href="#ml_utils.measure.chi_square">chi_square</a></code></li>
<li><code><a title="ml_utils.measure.csi" href="#ml_utils.measure.csi">csi</a></code></li>
<li><code><a title="ml_utils.measure.get_decilewise_counts" href="#ml_utils.measure.get_decilewise_counts">get_decilewise_counts</a></code></li>
<li><code><a title="ml_utils.measure.gsi" href="#ml_utils.measure.gsi">gsi</a></code></li>
<li><code><a title="ml_utils.measure.psi" href="#ml_utils.measure.psi">psi</a></code></li>
<li><code><a title="ml_utils.measure.quick_psi" href="#ml_utils.measure.quick_psi">quick_psi</a></code></li>
<li><code><a title="ml_utils.measure.standard_metrics" href="#ml_utils.measure.standard_metrics">standard_metrics</a></code></li>
<li><code><a title="ml_utils.measure.woe_bins" href="#ml_utils.measure.woe_bins">woe_bins</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>